import { LogEntry, LogLevel, LogCategory } from '@shared/schema';

// Mock log entries for testing
export const mockLogs: LogEntry[] = [
  {
    id: 1,
    timestamp: new Date('2024-03-15T10:15:00Z'),
    message: 'System started successfully',
    level: LogLevel.INFO,
    category: LogCategory.SYSTEM,
    source: 'server/index.ts',
    details: 'Server initialization complete',
    projectId: 1,
    userId: null,
    sessionId: '123456',
    duration: null,
    statusCode: null,
    endpoint: null,
    tags: ['startup', 'system'],
    formatted: 'INFO: System started successfully',
    color: '#4ade80',
    expanded: false
  },
  {
    id: 2,
    timestamp: new Date('2024-03-15T10:16:30Z'),
    message: 'User authentication successful',
    level: LogLevel.INFO,
    category: LogCategory.SECURITY,
    source: 'server/auth.ts',
    details: 'User authenticated with correct credentials',
    projectId: 1,
    userId: 1,
    sessionId: '123456',
    duration: 145,
    statusCode: 200,
    endpoint: '/api/auth/login',
    tags: ['authentication', 'security'],
    formatted: 'INFO: User authentication successful',
    color: '#4ade80',
    expanded: false
  },
  {
    id: 3,
    timestamp: new Date('2024-03-15T10:18:45Z'),
    message: 'API request failed: Rate limit exceeded',
    level: LogLevel.ERROR,
    category: LogCategory.API,
    source: 'server/services/openai.service.ts',
    details: 'OpenAI API returned 429 Too Many Requests',
    projectId: 1,
    userId: 1,
    sessionId: '123456',
    duration: 2345,
    statusCode: 429,
    endpoint: '/api/generate',
    tags: ['api', 'error', 'rate-limit'],
    formatted: 'ERROR: API request failed: Rate limit exceeded',
    color: '#ef4444',
    expanded: false
  },
  {
    id: 4,
    timestamp: new Date('2024-03-15T10:20:15Z'),
    message: 'Database query slow: Project retrieval',
    level: LogLevel.WARNING,
    category: LogCategory.DATABASE,
    source: 'server/storage.ts',
    details: 'Query took more than 500ms to execute',
    projectId: 1,
    userId: 1,
    sessionId: '123456',
    duration: 765,
    statusCode: null,
    endpoint: null,
    tags: ['database', 'performance'],
    formatted: 'WARNING: Database query slow: Project retrieval',
    color: '#f59e0b',
    expanded: false
  },
  {
    id: 5,
    timestamp: new Date('2024-03-15T10:25:00Z'),
    message: 'Memory usage high',
    level: LogLevel.DEBUG,
    category: LogCategory.PERFORMANCE,
    source: 'server/monitoring.ts',
    details: 'Current memory usage: 512MB',
    projectId: 1,
    userId: null,
    sessionId: null,
    duration: null,
    statusCode: null,
    endpoint: null,
    tags: ['memory', 'performance'],
    formatted: 'DEBUG: Memory usage high',
    color: '#94a3b8',
    expanded: false
  },
  {
    id: 6,
    timestamp: new Date('2024-03-15T10:30:00Z'),
    message: 'AI model loaded successfully',
    level: LogLevel.INFO,
    category: LogCategory.AI,
    source: 'server/services/ai.ts',
    details: 'Model: gpt-4o',
    projectId: 1,
    userId: null,
    sessionId: null,
    duration: 3250,
    statusCode: null,
    endpoint: null,
    tags: ['ai', 'model-loading'],
    formatted: 'INFO: AI model loaded successfully',
    color: '#4ade80',
    expanded: false
  }
];

// Mock log statistics for testing
export const mockLogStats = {
  totalCount: 56,
  countByLevel: {
    [LogLevel.DEBUG]: 10,
    [LogLevel.INFO]: 25,
    [LogLevel.WARNING]: 12,
    [LogLevel.ERROR]: 8,
    [LogLevel.CRITICAL]: 1
  },
  countByCategory: {
    [LogCategory.SYSTEM]: 8,
    [LogCategory.USER]: 15,
    [LogCategory.API]: 12,
    [LogCategory.DATABASE]: 6,
    [LogCategory.SECURITY]: 4,
    [LogCategory.PERFORMANCE]: 7,
    [LogCategory.AI]: 4
  },
  recentErrors: [
    mockLogs[2],
    {
      id: 7,
      timestamp: new Date('2024-03-15T11:15:00Z'),
      message: 'Failed to parse JSON response',
      level: LogLevel.ERROR,
      category: LogCategory.API,
      source: 'client/src/lib/openai.ts',
      details: 'SyntaxError: Unexpected token < in JSON at position 0',
      projectId: 1,
      userId: 1,
      sessionId: '123456',
      duration: null,
      statusCode: 200,
      endpoint: '/api/analyze',
      tags: ['api', 'parsing', 'error'],
      formatted: 'ERROR: Failed to parse JSON response',
      color: '#ef4444',
      expanded: false
    }
  ],
  performanceAverage: 245.6
};